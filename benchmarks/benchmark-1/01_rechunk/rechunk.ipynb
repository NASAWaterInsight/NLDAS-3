{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b31628-5535-45a6-bf97-ba0a7568a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import os\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6f0244-b7ca-4363-ab37-d77841635822",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'nasa-waterinsight'\n",
    "directory = 'NLDAS3/forcing/temp-chunk/timechunk01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ea3ec5-4f00-4917-97cb-8347813a20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3fsfs = s3fs.S3FileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9460d-b78c-4f1b-ba7e-4a64a5ad801e",
   "metadata": {},
   "source": [
    "**TODO:** This is faster if the file with the closest matching chunk shape (at least in the time dimension) to rechunk and write the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86d4d8c-5bc7-4aa1-b94d-44fd2d60f9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.5 s, sys: 1.99 s, total: 7.49 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = s3fsfs.glob(f's3://{bucket}/{directory}/*.nc')\n",
    "ds = xr.open_dataset(s3fsfs.open(f's3://{files[0]}'), chunks={})\n",
    "da = ds['Tair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a388bd9-47aa-4fe2-81a8-9d853dbb62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunked_file(\n",
    "    da: xr.DataArray, \n",
    "    s3fsfs: s3fs.S3FileSystem,\n",
    "    bucket: str = 'nasa-eodc-scratch',\n",
    "    time_chunk=24, \n",
    "    lat=50, \n",
    "    lon=90, \n",
    "    variable_name='Tair',\n",
    "    output_dir='test_files',\n",
    "    upload_to_s3=True,\n",
    "    verbose=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a NetCDF file with specified chunking and optionally upload to S3.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    da : xarray.DataArray\n",
    "        The input data array to be chunked.\n",
    "    bucket : str\n",
    "        S3 bucket name.\n",
    "    s3fsfs : s3fs.S3FileSystem\n",
    "        S3 filesystem object.\n",
    "    time_chunk : int, default 24\n",
    "        Number of time steps per chunk.\n",
    "    lat : int\n",
    "        Latitude chunk size.\n",
    "    lon : int\n",
    "        Longitude chunk size.\n",
    "    variable_name : str, default 'tair'\n",
    "        Name of the variable in the file.\n",
    "    output_dir : str, default 'chunking_test'\n",
    "        Directory in S3 bucket to store the file.\n",
    "    upload_to_s3 : bool, default True\n",
    "        Whether to upload the file to S3.\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress information.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with file paths and timing information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create chunks dictionary\n",
    "    chunks = {'time': time_chunk, 'lat': lat, 'lon': lon}\n",
    "    chunk_shape_as_string = ('_').join([f\"{k}{v}\" for k, v in chunks.items()])\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = f\"{chunk_shape_as_string}_{variable_name}.nc\"\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Creating file with chunks: {chunks}\")\n",
    "        print(f\"Output filename: {filename}\")\n",
    "    \n",
    "    # Time the chunking and file writing process\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply chunking\n",
    "    chunked_da = da.chunk(chunks=chunks)\n",
    "    encoding = da.encoding.copy()\n",
    "    del encoding['source']\n",
    "    del encoding['original_shape']\n",
    "    del encoding['preferred_chunks']\n",
    "    encoding['chunksizes'] = tuple(chunks.values())\n",
    "    \n",
    "    # Write to NetCDF file\n",
    "    chunked_da.to_netcdf(filename, mode='w', encoding={variable_name: encoding})\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"File created in {elapsed_time:.2f} seconds\")\n",
    "    \n",
    "    # Upload to S3 if requested\n",
    "    s3_path = None\n",
    "    \n",
    "    if upload_to_s3:\n",
    "        s3_path = f's3://{bucket}/NLDAS/netcdf/{output_dir}/{filename}'\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Uploading to {s3_path}...\")\n",
    "        \n",
    "        s3fsfs.put(filename, s3_path)\n",
    "    \n",
    "    # Return info about the file\n",
    "    return {\n",
    "        'local_path': os.path.abspath(filename),\n",
    "        's3_path': s3_path,\n",
    "        'chunks': chunks,\n",
    "        'file_size_mb': os.path.getsize(filename) / (1024 * 1024),\n",
    "        'processing_time': elapsed_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda9d2af-ab7b-4406-9f2b-327f56fc2460",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_configurations = [\n",
    "    # 1 chunk for all time steps\n",
    "    dict(time_chunk=24, lat=50, lon=90),\n",
    "    dict(time_chunk=24, lat=100, lon=180),\n",
    "    dict(time_chunk=24, lat=500, lon=900),\n",
    "    dict(time_chunk=24, lat=1000, lon=1800),\n",
    "    # 6 timesteps per chunk\n",
    "    dict(time_chunk=6, lat=100, lon=180),\n",
    "    dict(time_chunk=6, lat=200, lon=360),\n",
    "    dict(time_chunk=6, lat=1000, lon=1800),\n",
    "    dict(time_chunk=6, lat=2000, lon=3600),\n",
    "    # 1 timestep per chunk\n",
    "    dict(time_chunk=1, lat=250, lon=450),\n",
    "    dict(time_chunk=1, lat=500, lon=900),\n",
    "    dict(time_chunk=1, lat=2500, lon=4500),\n",
    "    dict(time_chunk=1, lat=5000, lon=9000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a786656b-8b6f-4239-a917-ba80537fdaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file with chunks: {'time': 1, 'lat': 250, 'lon': 450}\n",
      "Output filename: time1_lat250_lon450_Tair.nc\n",
      "File created in 594.83 seconds\n",
      "Uploading to s3://nasa-eodc-scratch/NLDAS/netcdf/test_files/time1_lat250_lon450_Tair.nc...\n"
     ]
    }
   ],
   "source": [
    "for config in chunk_configurations[0]:\n",
    "    create_chunked_file(da=da, s3fsfs=s3fsfs, **config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
